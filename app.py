# %%writefile komutu, bu hÃ¼crenin iÃ§eriÄŸini 'app.py' adlÄ± bir dosyaya kaydeder.

import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import re
import string
import emoji
import nltk
from nltk.corpus import stopwords
import pandas as pd
import warnings

# Gereksiz uyarÄ±larÄ± gizle
warnings.filterwarnings("ignore")

# --- 1. Gerekli Verilerin Kurulumu ---
# NLTK stopwords (etkisiz kelimeler) listesini indirme
@st.cache_resource
def load_nltk_data():
    try:
        nltk.data.find('corpora/stopwords')
    except LookupError:
        nltk.download('stopwords')
load_nltk_data()
turkce_stopwords = stopwords.words('turkish')


# !!! DEÄÄ°ÅTÄ°RÄ°N !!!
# Modeli Hugging Face Hub'dan Ã§ekmek iÃ§in yolu gÃ¼ncelleyin.
# 'KULLANICI_ADINIZ' kÄ±smÄ±nÄ± Hugging Face kullanÄ±cÄ± adÄ±nÄ±zla deÄŸiÅŸtirin.
# (Ã–nceki konuÅŸmalarÄ±mÄ±zdan yola Ã§Ä±karak 'Scaran' olduÄŸunu varsayÄ±yorum)
MODEL_YOLU = "savasy/bert-base-turkish-sentiment-cased"
#MODEL_YOLU = "Scaran/DijitalSessizlik-BERT-Modeli" 
# Ã–rn: MODEL_YOLU = "Scaran/DijitalSessizlik-BERT-Modeli"

# SÄ±nÄ±f isimlerimizi tanÄ±mlÄ±yoruz
SINIF_ADLARI = ['AÃ§Ä±k ZorbalÄ±k', 'Ã–rtÃ¼k ZorbalÄ±k', 'NÃ¶tr']


# --- 2. Metin Ã–n Ä°ÅŸleme Fonksiyonu (AdÄ±m 1'deki ile aynÄ±) ---
def preprocess_text(text):
    text = str(text).lower() # Girdiyi string'e zorla ve kÃ¼Ã§Ã¼k harfe Ã§evir
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'@\w+', '', text)
    text = text.replace('#', '')
    text = emoji.demojize(text, language='tr')
    text = text.translate(str.maketrans('', '', string.punctuation))
    text = re.sub(r'\d+', '', text)
    text_tokens = text.split()
    text_without_stopwords = [word for word in text_tokens if not word in turkce_stopwords]
    text = ' '.join(text_without_stopwords)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# --- 3. Model YÃ¼kleme (Cache ile) ---
@st.cache_resource
def load_model(model_path):
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSequenceClassification.from_pretrained(model_path)
        model.eval() # Modeli deÄŸerlendirme (inference) moduna al
        st.success("Model baÅŸarÄ±yla Hugging Face Hub'dan yÃ¼klendi.")
        return model, tokenizer
    except Exception as e:
        st.error(f"Model yÃ¼klenirken bir hata oluÅŸtu: {e}")
        st.info(f"Model Yolu: {model_path}")
        st.info("LÃ¼tfen modelinizin Hugging Face Hub'da 'Public' (Herkese AÃ§Ä±k) olarak ayarlandÄ±ÄŸÄ±ndan emin olun.")
        return None, None

# --- 4. Streamlit ArayÃ¼z Kodu ---
st.title("Dijital Sessizlik: Siber ZorbalÄ±k Tespit Modeli (BERT)")
st.subheader("TÃœBÄ°TAK 2204-A Projesi Prototipi")

# Modeli ve tokenizer'Ä± yÃ¼kle
model, tokenizer = load_model(MODEL_YOLU)

if model and tokenizer:
    # KullanÄ±cÄ±dan metin giriÅŸi al
    user_input = st.text_area("LÃ¼tfen analiz edilecek metni girin:", 
                              "BugÃ¼n hava Ã§ok gÃ¼zel ama bazÄ± insanlar gerÃ§ekten can sÄ±kÄ±cÄ± olabiliyor.", 
                              height=150)

    # "SÄ±nÄ±flandÄ±r" butonuna basÄ±ldÄ±ÄŸÄ±nda...
    if st.button("SÄ±nÄ±flandÄ±r"):
        if user_input:
            with st.spinner("Metin iÅŸleniyor ve model tahmini yapÄ±lÄ±yor..."):
                # 1. Girdiyi temizle
                processed_text = preprocess_text(user_input)
                
                # 2. Modeli hazÄ±rla (Tokenize et)
                inputs = tokenizer(processed_text, 
                                   return_tensors="pt", 
                                   truncation=True, 
                                   padding=True, 
                                   max_length=128)
                
                # 3. Tahmin yap
                with torch.no_grad(): # Gradient hesaplamalarÄ±nÄ± kapat (hÄ±zlandÄ±rÄ±r)
                    logits = model(**inputs).logits
                
                # 4. SonuÃ§larÄ± iÅŸle
                probabilities = torch.softmax(logits, dim=1)
                confidence = torch.max(probabilities).item()
                predicted_class_id = torch.argmax(probabilities, dim=1).item()
                predicted_class_name = SINIF_ADLARI[predicted_class_id]
                
                # 5. SonuÃ§larÄ± gÃ¶ster
                st.subheader("SÄ±nÄ±flandÄ±rma Sonucu:")
                
                if predicted_class_name == 'AÃ§Ä±k ZorbalÄ±k':
                    st.error(f"ğŸš¨ TESPÄ°T EDÄ°LDÄ°: {predicted_class_name} ({confidence*100:.2f}%)")
                    st.write("Bu metin, belirli bir kimliÄŸi (yaÅŸ, Ä±rk, cinsiyet vb.) hedef alan, bariz hakaret veya nefret sÃ¶ylemi iÃ§ermektedir.")
                elif predicted_class_name == 'Ã–rtÃ¼k ZorbalÄ±k':
                    st.warning(f"âš ï¸ TESPÄ°T EDÄ°LDÄ°: {predicted_class_name} ({confidence*100:.2f}%)")
                    st.write("Bu metin, doÄŸrudan hakaret iÃ§ermese de alay, ima, dÄ±ÅŸlama veya genel taciz unsurlarÄ± barÄ±ndÄ±ran 'gÃ¶rÃ¼nmeyen' zorbalÄ±k iÃ§ermektedir.")
                else: # NÃ¶tr
                    st.success(f"âœ… TESPÄ°T EDÄ°LDÄ°: {predicted_class_name} ({confidence*100:.2f}%)")
                    st.write("Bu metinde belirgin bir zorbalÄ±k iÃ§eriÄŸi tespit edilmemiÅŸtir.")
                
                # DetaylÄ± skorlarÄ± gÃ¶ster
                st.subheader("Model GÃ¼ven SkorlarÄ±:")
                prob_df = pd.DataFrame(probabilities.numpy(), columns=SINIF_ADLARI)
                st.dataframe(prob_df.style.format("{:.2%}"))

                st.subheader("Ä°ÅŸlem DetaylarÄ±:")
                st.text(f"Orijinal Metin: {user_input}")
                st.text(f"TemizlenmiÅŸ Metin: {processed_text}")
        else:
            st.warning("LÃ¼tfen analiz etmek iÃ§in bir metin girin.")
